{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json + CSV 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "['_JSON 1 Instagram JSON File/1day1poem.json', '_JSON 1 Instagram JSON File/9_ruumy.json', '_JSON 1 Instagram JSON File/ajaegeul.json', '_JSON 1 Instagram JSON File/book_jjung.json', '_JSON 1 Instagram JSON File/by_yell7.json']\n",
      "\n",
      "70\n",
      "['_JSON 2 Image OCR Result CSV File/1day1poem.csv', '_JSON 2 Image OCR Result CSV File/9_ruumy.csv', '_JSON 2 Image OCR Result CSV File/ajaegeul.csv', '_JSON 2 Image OCR Result CSV File/book_jjung.csv', '_JSON 2 Image OCR Result CSV File/by_yell7.csv']\n"
     ]
    }
   ],
   "source": [
    "# 상위 폴더로부터 하위 디렉토리 리스트로 뽑아주는 함수\n",
    "def load_directory_data(pwd):\n",
    "\n",
    "    file_path_list = []\n",
    "    \n",
    "    # 디렉토리, 디렉토리 내 폴더 리스트, 파일 리스트\n",
    "    for path,dirs,files in os.walk(pwd):\n",
    "        \n",
    "        for f in files:           \n",
    "            file_path = path + '/' +f\n",
    "            file_path_list.append(file_path) \n",
    "            \n",
    "    print(len(file_path_list))\n",
    "    return file_path_list\n",
    "\n",
    "FILE_1 = load_directory_data(\"_JSON 1 Instagram JSON File\")\n",
    "print(FILE_1[:5])\n",
    "print()\n",
    "FILE_2 = load_directory_data(\"_JSON 2 Image OCR Result CSV File\")\n",
    "print(FILE_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(FILE_PATH):\n",
    "    \n",
    "    # read json\n",
    "    with open(FILE_PATH, encoding='UTF8') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        \n",
    "    user_name = os.path.basename(FILE_PATH)[:-5]\n",
    "    insta_df = pd.DataFrame()\n",
    "\n",
    "    for d in json_data:\n",
    "        hashtag_list = []\n",
    "        caption_txt = ''\n",
    "        insta = pd.DataFrame()\n",
    "\n",
    "        # caption 해시태그 가져오기\n",
    "        if 'caption' in d:\n",
    "            # 간단한 전처리\n",
    "            caption_txt = d['caption'].replace('\\n',' ')\n",
    "            if caption_txt[0] == '-':\n",
    "                caption_txt = caption_txt[1:]\n",
    "            caption_txt = caption_txt.strip()\n",
    "            hashtag_list = re.findall(r\"#(\\w+)\", caption_txt) \n",
    "\n",
    "        # 기존 코드는 caption이 없을 경우 작동 못함\n",
    "        # comments에서 해시태그 가져오기 \n",
    "        if 'comments' in d:\n",
    "            comments = d['comments']\n",
    "            for c in list(d['comments']):\n",
    "                # 댓글 작성자가 인스타 유저라면 코멘트 가져오기\n",
    "                if c['author'] == userName:\n",
    "                    comment_txt = c['comment']\n",
    "                    hashtag_list = re.findall(r\"#(\\w+)\", comment_txt)   \n",
    "                    #태그가 저장이 되었다면 for 문 종료\n",
    "                    if len(hashtag_list) != 0:\n",
    "                        break\n",
    "        \n",
    "        # 매 loop마다 데이터 쌓기\n",
    "        insta = pd.DataFrame({'USER_ID': user_name,\n",
    "                              'CONTENT_ID': d['key'].split('/')[-2],\n",
    "                              'Content_txt': caption_txt,\n",
    "                              'Hashtags' : [hashtag_list]})\n",
    "        insta_df = insta_df.append(insta)\n",
    "        insta_df = insta_df.reset_index(drop=True)\n",
    "\n",
    "    return insta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_csv(FILE_PATH):\n",
    "    data = pd.read_csv(FILE_PATH,encoding = 'utf-8' )\n",
    "    data = data.iloc[:,:2]\n",
    "    data.columns = ['CONTENT_IMAGE_ID','Image_Content_txt']\n",
    "    # 게시글 아이디 \n",
    "    data['CONTENT_IMAGE_ID'] = data['CONTENT_IMAGE_ID'].apply(lambda x : x[:-4])\n",
    "    # 게시글에 여러장 있을 경우 추가 구분\n",
    "    data['CONTENT_ID'] =  data['CONTENT_IMAGE_ID'].apply(lambda x : x[:-2])\n",
    "    data['USER_ID'] = os.path.basename(FILE_PATH)[:-4]\n",
    "    data = data[['USER_ID','CONTENT_ID','CONTENT_IMAGE_ID','Image_Content_txt']]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1day1poem\n",
      "9_ruumy\n",
      "ajaegeul\n",
      "book_jjung\n",
      "by_yell7\n",
      "chaemss\n",
      "choejemin_pvc\n",
      "choi_dol\n",
      "churihyung\n",
      "c___w00\n",
      "dajeong_geul\n",
      "day_in_scene\n",
      "dden_by\n",
      "dearbliss2\n",
      "deep_bak\n",
      "dh_solace\n",
      "doodler_1211\n",
      "funnyprince81\n",
      "galin001\n",
      "geulgomm\n",
      "guitarlist._w.g\n",
      "hanl_i\n",
      "haru11__\n",
      "haru_line\n",
      "h_01_00_a\n",
      "h_jongduck\n",
      "iamkimbunny\n",
      "insightsh\n",
      "insta_book_cafe\n",
      "insum_\n",
      "iris_daily_writing\n",
      "jaulounge\n",
      "jea.therapy\n",
      "jinagann\n",
      "jinsimgeul\n",
      "jms14219\n",
      "kiheaven97\n",
      "kim_friendship_01.19\n",
      "kim_hanwoong\n",
      "laenari\n",
      "marom__story\n",
      "me______new\n",
      "moonfatalae\n",
      "namumind\n",
      "ok_yeong_\n",
      "poem_1000_\n",
      "reason_that_i_live\n",
      "riosniper114\n",
      "seesaw517\n",
      "see_min0727\n",
      "seodeokjun\n",
      "seokgeul\n",
      "shine_like_september\n",
      "syhiphop\n",
      "taeeeseok\n",
      "taehee_editor\n",
      "tale_tree_\n",
      "violet_hoho\n",
      "w.gahee\n",
      "w.ojoo\n",
      "wan_e0612\n",
      "woojin_940205\n",
      "worker_poet\n",
      "writer.jieun\n",
      "writing_peach.97\n",
      "youandme.211\n",
      "yumradio\n",
      "_illusion_30\n",
      "_neobam\n",
      "총 데이터 개수 31613\n"
     ]
    }
   ],
   "source": [
    "def merging(FILE_LIST1,FILE_LIST2):\n",
    "    total_data = 0\n",
    "    for f_json in FILE_LIST1:\n",
    "        user_json = os.path.basename(f_json)[:-5]\n",
    "        insta_data = read_json(f_json)\n",
    "        for f_csv in FILE_LIST2:\n",
    "            user_csv = os.path.basename(f_csv)[:-4]\n",
    "            # 유저 같다면\n",
    "            if user_json == user_csv:\n",
    "                ocr_data = read_csv(f_csv)\n",
    "                print(user_csv)\n",
    "                merge_df = pd.merge(insta_data,ocr_data,on=['USER_ID','CONTENT_ID'],how='inner')\n",
    "                merge_df = merge_df[['USER_ID','CONTENT_ID','CONTENT_IMAGE_ID','Image_Content_txt','Content_txt','Hashtags']]\n",
    "                merge_df.to_csv('Final_Data/' + user_json + '.csv', encoding='utf-8-sig')\n",
    "                total_data += len(merge_df)\n",
    "    print(\"총 데이터 개수\",total_data)\n",
    "merging(FILE_1,FILE_2)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 데이터로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>CONTENT_ID</th>\n",
       "      <th>CONTENT_IMAGE_ID</th>\n",
       "      <th>Image_Content_txt</th>\n",
       "      <th>Content_txt</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B0-ju6tlJ0H</td>\n",
       "      <td>B0-ju6tlJ0H_0</td>\n",
       "      <td>XXL 칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다. 저 뺏뻣한 것을 ...</td>\n",
       "      <td>칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다.  저 뻣뻣한 것을 다 벌...</td>\n",
       "      <td>['가능하면1일1시', '190706', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B00P31KFH8n</td>\n",
       "      <td>B00P31KFH8n_0</td>\n",
       "      <td>아무도 미워하지 않으니 아무도좋다지 않는다. 요즘은 미운 것이 같아야 벗이라더라. ...</td>\n",
       "      <td>아무도 미워하지 않으니 아무도 좋다지 않는다.  요즘은 미운 것이 같아야 벗이라더라...</td>\n",
       "      <td>['가능하면1일1시', '190701', '임재건', '다시는사랑이없을줄알았습니다'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B013_0tlKDz</td>\n",
       "      <td>B013_0tlKDz_0</td>\n",
       "      <td>어제 초승이던 것이 오늘 보름이겠느냐만 너는 밤하늘 둥근 빛이라도 달은 아니므로 벌...</td>\n",
       "      <td>어제 초승이던 것이 오늘 보름이겠느냐만  너는 밤하늘 둥근 빛이라도 달은 아니므로 ...</td>\n",
       "      <td>['가능하면1일1시', '190807', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B02zFDJleE9</td>\n",
       "      <td>B02zFDJleE9_1</td>\n",
       "      <td>비 온다니 장룡이 뼈격뼈걱 의자가 빠거덕뻐거덕 할머니 흉내 낸다. 삐걱삐걱 삐거덕삐...</td>\n",
       "      <td>비 온다니 장롱이 삐걱삐걱 의자가 삐거덕삐거덕 할머니 흉내 낸다.  삐걱삐걱 삐거덕...</td>\n",
       "      <td>['가능하면1일1시', '190702', '임재건', '다시는사랑이없을줄알았습니다'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B04cS4mFCfS</td>\n",
       "      <td>B04cS4mFCfS_0</td>\n",
       "      <td>저것은 누가놓친 알인가. 새가 돼야할 것이 꽃이 되어 있구나. 바람에 나는듯 살랑인...</td>\n",
       "      <td>저것은 누가 놓친 알인가.  새가 돼야 할 것이 꽃이 되어 있구나.  바람에 나는 ...</td>\n",
       "      <td>['가능하면1일1시', '190808', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID   CONTENT_ID CONTENT_IMAGE_ID  \\\n",
       "0  1day1poem  B0-ju6tlJ0H    B0-ju6tlJ0H_0   \n",
       "1  1day1poem  B00P31KFH8n    B00P31KFH8n_0   \n",
       "2  1day1poem  B013_0tlKDz    B013_0tlKDz_0   \n",
       "3  1day1poem  B02zFDJleE9    B02zFDJleE9_1   \n",
       "4  1day1poem  B04cS4mFCfS    B04cS4mFCfS_0   \n",
       "\n",
       "                                   Image_Content_txt  \\\n",
       "0  XXL 칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다. 저 뺏뻣한 것을 ...   \n",
       "1  아무도 미워하지 않으니 아무도좋다지 않는다. 요즘은 미운 것이 같아야 벗이라더라. ...   \n",
       "2  어제 초승이던 것이 오늘 보름이겠느냐만 너는 밤하늘 둥근 빛이라도 달은 아니므로 벌...   \n",
       "3  비 온다니 장룡이 뼈격뼈걱 의자가 빠거덕뻐거덕 할머니 흉내 낸다. 삐걱삐걱 삐거덕삐...   \n",
       "4  저것은 누가놓친 알인가. 새가 돼야할 것이 꽃이 되어 있구나. 바람에 나는듯 살랑인...   \n",
       "\n",
       "                                         Content_txt  \\\n",
       "0  칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다.  저 뻣뻣한 것을 다 벌...   \n",
       "1  아무도 미워하지 않으니 아무도 좋다지 않는다.  요즘은 미운 것이 같아야 벗이라더라...   \n",
       "2  어제 초승이던 것이 오늘 보름이겠느냐만  너는 밤하늘 둥근 빛이라도 달은 아니므로 ...   \n",
       "3  비 온다니 장롱이 삐걱삐걱 의자가 삐거덕삐거덕 할머니 흉내 낸다.  삐걱삐걱 삐거덕...   \n",
       "4  저것은 누가 놓친 알인가.  새가 돼야 할 것이 꽃이 되어 있구나.  바람에 나는 ...   \n",
       "\n",
       "                                            Hashtags  \n",
       "0  ['가능하면1일1시', '190706', '임재건', '1일1시', '다시는사랑이없...  \n",
       "1  ['가능하면1일1시', '190701', '임재건', '다시는사랑이없을줄알았습니다'...  \n",
       "2  ['가능하면1일1시', '190807', '임재건', '1일1시', '다시는사랑이없...  \n",
       "3  ['가능하면1일1시', '190702', '임재건', '다시는사랑이없을줄알았습니다'...  \n",
       "4  ['가능하면1일1시', '190808', '임재건', '1일1시', '다시는사랑이없...  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_Final = load_directory_data(\"Final_Data\")\n",
    "total_df = pd.DataFrame()\n",
    "\n",
    "for f in FILE_Final:\n",
    "    df =pd.read_csv(f,encoding = 'utf-8')\n",
    "    df = df.iloc[:,1:]\n",
    "    total_df = total_df.append(df,sort=True)\n",
    "    \n",
    "total_df = total_df.iloc[:,:-1]\n",
    "total_df = total_df[['USER_ID','CONTENT_ID', 'CONTENT_IMAGE_ID','Image_Content_txt','Content_txt', 'Hashtags']]\n",
    "total_df = total_df.sort_values(['USER_ID','CONTENT_ID','CONTENT_IMAGE_ID'])\n",
    "total_df = total_df.reset_index(drop = True)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_df.to_csv(\"Total_Final_Data_v1.csv\",encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 같은 CONTENT_ID 끼리 데이터 묶어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajou\\Anaconda3\\envs\\python\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: pd.groupby() is deprecated and will be removed; Please use the Series.groupby() or DataFrame.groupby() methods\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>CONTENT_ID</th>\n",
       "      <th>Image_Content_txt</th>\n",
       "      <th>Content_txt</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B0-ju6tlJ0H</td>\n",
       "      <td>XXL 칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다. 저 뺏뻣한 것을 ...</td>\n",
       "      <td>칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다.  저 뻣뻣한 것을 다 벌...</td>\n",
       "      <td>['가능하면1일1시', '190706', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B00P31KFH8n</td>\n",
       "      <td>아무도 미워하지 않으니 아무도좋다지 않는다. 요즘은 미운 것이 같아야 벗이라더라. ...</td>\n",
       "      <td>아무도 미워하지 않으니 아무도 좋다지 않는다.  요즘은 미운 것이 같아야 벗이라더라...</td>\n",
       "      <td>['가능하면1일1시', '190701', '임재건', '다시는사랑이없을줄알았습니다'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B013_0tlKDz</td>\n",
       "      <td>어제 초승이던 것이 오늘 보름이겠느냐만 너는 밤하늘 둥근 빛이라도 달은 아니므로 벌...</td>\n",
       "      <td>어제 초승이던 것이 오늘 보름이겠느냐만  너는 밤하늘 둥근 빛이라도 달은 아니므로 ...</td>\n",
       "      <td>['가능하면1일1시', '190807', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B02zFDJleE9</td>\n",
       "      <td>비 온다니 장룡이 뼈격뼈걱 의자가 빠거덕뻐거덕 할머니 흉내 낸다. 삐걱삐걱 삐거덕삐...</td>\n",
       "      <td>비 온다니 장롱이 삐걱삐걱 의자가 삐거덕삐거덕 할머니 흉내 낸다.  삐걱삐걱 삐거덕...</td>\n",
       "      <td>['가능하면1일1시', '190702', '임재건', '다시는사랑이없을줄알았습니다'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B04cS4mFCfS</td>\n",
       "      <td>저것은 누가놓친 알인가. 새가 돼야할 것이 꽃이 되어 있구나. 바람에 나는듯 살랑인...</td>\n",
       "      <td>저것은 누가 놓친 알인가.  새가 돼야 할 것이 꽃이 되어 있구나.  바람에 나는 ...</td>\n",
       "      <td>['가능하면1일1시', '190808', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID   CONTENT_ID                                  Image_Content_txt  \\\n",
       "0  1day1poem  B0-ju6tlJ0H  XXL 칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다. 저 뺏뻣한 것을 ...   \n",
       "1  1day1poem  B00P31KFH8n  아무도 미워하지 않으니 아무도좋다지 않는다. 요즘은 미운 것이 같아야 벗이라더라. ...   \n",
       "2  1day1poem  B013_0tlKDz  어제 초승이던 것이 오늘 보름이겠느냐만 너는 밤하늘 둥근 빛이라도 달은 아니므로 벌...   \n",
       "3  1day1poem  B02zFDJleE9  비 온다니 장룡이 뼈격뼈걱 의자가 빠거덕뻐거덕 할머니 흉내 낸다. 삐걱삐걱 삐거덕삐...   \n",
       "4  1day1poem  B04cS4mFCfS  저것은 누가놓친 알인가. 새가 돼야할 것이 꽃이 되어 있구나. 바람에 나는듯 살랑인...   \n",
       "\n",
       "                                         Content_txt  \\\n",
       "0  칫솔은 새 것인데 솔질이 새 것 아니니 잇몸에 피가 난다.  저 뻣뻣한 것을 다 벌...   \n",
       "1  아무도 미워하지 않으니 아무도 좋다지 않는다.  요즘은 미운 것이 같아야 벗이라더라...   \n",
       "2  어제 초승이던 것이 오늘 보름이겠느냐만  너는 밤하늘 둥근 빛이라도 달은 아니므로 ...   \n",
       "3  비 온다니 장롱이 삐걱삐걱 의자가 삐거덕삐거덕 할머니 흉내 낸다.  삐걱삐걱 삐거덕...   \n",
       "4  저것은 누가 놓친 알인가.  새가 돼야 할 것이 꽃이 되어 있구나.  바람에 나는 ...   \n",
       "\n",
       "                                            Hashtags  \n",
       "0  ['가능하면1일1시', '190706', '임재건', '1일1시', '다시는사랑이없...  \n",
       "1  ['가능하면1일1시', '190701', '임재건', '다시는사랑이없을줄알았습니다'...  \n",
       "2  ['가능하면1일1시', '190807', '임재건', '1일1시', '다시는사랑이없...  \n",
       "3  ['가능하면1일1시', '190702', '임재건', '다시는사랑이없을줄알았습니다'...  \n",
       "4  ['가능하면1일1시', '190808', '임재건', '1일1시', '다시는사랑이없...  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_df_v2 = pd.groupby(total_df[['USER_ID','CONTENT_ID','Image_Content_txt','Content_txt','Hashtags']],\n",
    "           ['USER_ID','CONTENT_ID']).sum().reset_index(drop=False)\n",
    "\n",
    "Total_df_v2 = Total_df_v2.sort_values(['USER_ID','CONTENT_ID'])\n",
    "Total_df_v2 = Total_df_v2.reset_index(drop = True)\n",
    "Total_df_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total_df_v2.to_csv(\"Total_Final_Data_v2_concatTxt.csv\",encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
